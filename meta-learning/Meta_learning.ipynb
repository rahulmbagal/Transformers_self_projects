{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c673db-447e-4830-82b6-baa34b833477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ffa7c-a95a-4c89-b093-3ebabec02fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825fcf54-3439-42f6-b56a-8a4ba356c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_group1_data(n=1000):\n",
    "    geo_regions = [\"North America\", \"EMEA\", \"APAC\", \"LATAM\"]\n",
    "    countries = {\n",
    "        \"North America\": [\"USA\", \"Canada\"],\n",
    "        \"EMEA\": [\"Germany\", \"UK\", \"France\"],\n",
    "        \"APAC\": [\"India\", \"Japan\", \"Singapore\"],\n",
    "        \"LATAM\": [\"Brazil\", \"Mexico\", \"Chile\"]\n",
    "    }\n",
    "    products = [\"AutoCAD\", \"Revit\", \"Fusion 360\", \"Civil 3D\", \"Inventor\"]\n",
    "    personas = [\"Engineer\", \"Architect\", \"Designer\", \"Contractor\", \"Student\"]\n",
    "    domain_types = [\".com\", \".org\", \".net\", \".edu\"]\n",
    "    evt_types = [\"Page_Visit\", \"Email_Click\", \"Webinar_Attend\", \"Form_Submit\"]\n",
    "\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        geo = random.choice(geo_regions)\n",
    "        country = random.choice(countries[geo])\n",
    "        product = random.choice(products)\n",
    "        persona = random.choice(personas)\n",
    "        domain = random.choice(domain_types)\n",
    "        evt = random.choice(evt_types)\n",
    "\n",
    "        # behavioral data\n",
    "        page_visits = np.random.poisson(8)\n",
    "        clicks = np.random.poisson(3)\n",
    "        session_duration = round(np.random.normal(2.5, 1.0), 2)\n",
    "        email_opens = np.random.randint(0, 6)\n",
    "        form_submissions = np.random.randint(0, 3)\n",
    "        ad_impressions = np.random.randint(10, 80)\n",
    "\n",
    "        # conversion probability logic\n",
    "        engagement_score = (\n",
    "            0.4 * page_visits + 0.5 * clicks + 0.3 * email_opens + 0.8 * form_submissions\n",
    "        )\n",
    "        prob = 1 / (1 + np.exp(-0.1 * (engagement_score - 5)))\n",
    "        converted = np.random.binomial(1, prob)\n",
    "\n",
    "        rows.append([\n",
    "            f\"L{i+1000}\", geo, country, product, persona, domain,\n",
    "            page_visits, clicks, session_duration, evt,\n",
    "            email_opens, form_submissions, ad_impressions, converted\n",
    "        ])\n",
    "\n",
    "    cols = [\"lead_id\", \"geo_region\", \"country\", \"product_interest\", \"persona_audience_role\",\n",
    "            \"domain_type\", \"page_visits\", \"clicks\", \"avg_session_duration\", \"evt_event_type\",\n",
    "            \"email_opens\", \"form_submissions\", \"ad_impressions\", \"converted\"]\n",
    "\n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b8946-3906-4ef6-8481-18f323933b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e331b5dd-39a4-4930-87ae-9753b9888f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_group2_data(n=1000):\n",
    "    nag_regions = [\"NAMER\", \"EMEA\", \"APAC\", \"LATAM\"]\n",
    "    industries = [\"Manufacturing\", \"Construction\", \"Design\", \"Education\", \"Infrastructure\"]\n",
    "    products = [\"AutoCAD\", \"Revit\", \"Fusion 360\", \"Civil 3D\", \"Inventor\"]\n",
    "    sap_product_lines = [\"AEC\", \"D&M\", \"M&E\"]\n",
    "    offering_subcategories = [\"Cloud Products\", \"Product Subscription\", \"Maintenance\"]\n",
    "    license_terms = [\"Annual\", \"Monthly\"]\n",
    "    billing_terms = [\"Annual - 1Y\", \"Annual - 2Y\", \"Annual - 3Y\", \"Monthly\"]\n",
    "    online_offline = [\"Online\", \"Offline\"]\n",
    "    crm_tiers = [\"Gold\", \"Silver\", \"Bronze\"]\n",
    "    renewal_statuses = [\"Active\", \"Expired\", \"Churned\"]\n",
    "\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        nag = random.choice(nag_regions)\n",
    "        geo = {\n",
    "            \"NAMER\": \"North America\", \"EMEA\": \"EMEA\", \"APAC\": \"APAC\", \"LATAM\": \"LATAM\"\n",
    "        }[nag]\n",
    "        country = random.choice([\"USA\", \"Canada\", \"Germany\", \"UK\", \"India\", \"Japan\", \"Brazil\", \"Mexico\"])\n",
    "        product = random.choice(products)\n",
    "        persona = random.choice([\"Engineer\", \"Architect\", \"Designer\", \"Contractor\", \"Student\"])\n",
    "        domain_type = random.choice([\".com\", \".org\", \".net\", \".edu\"])\n",
    "        evt = random.choice([\"Page_Visit\", \"Email_Click\", \"Webinar_Attend\", \"Form_Submit\"])\n",
    "\n",
    "        # account-level features\n",
    "        account_id = f\"A{3000+i}\"\n",
    "        account_domain = f\"{product.lower()}-{i}.com\"\n",
    "        industry = random.choice(industries)\n",
    "        company_size = np.random.randint(50, 5000)\n",
    "        annual_revenue = company_size * np.random.randint(5000, 15000)\n",
    "        acv = np.random.randint(20000, 150000)\n",
    "        num_licenses = max(1, int(acv / np.random.randint(1500, 3000)))\n",
    "        num_products_owned = np.random.randint(1, 5)\n",
    "        products_purchased = \", \".join(random.sample(products, num_products_owned))\n",
    "\n",
    "        license_term = random.choice(license_terms)\n",
    "        billing_term = random.choice(billing_terms)\n",
    "        online = random.choice(online_offline)\n",
    "        offering = random.choice(offering_subcategories)\n",
    "        sap_line = random.choice(sap_product_lines)\n",
    "\n",
    "        crm_tier = random.choice(crm_tiers)\n",
    "        account_age = np.random.randint(6, 72)\n",
    "        engagement_score = np.clip(np.random.normal(0.6, 0.2), 0, 1)\n",
    "        tickets = np.random.randint(0, 5)\n",
    "        renewal_status = random.choices(renewal_statuses, weights=[0.6, 0.25, 0.15])[0]\n",
    "\n",
    "        # lead-level activity\n",
    "        page_visits = np.random.poisson(10)\n",
    "        clicks = np.random.poisson(4)\n",
    "        session_duration = round(np.random.normal(3.0, 1.0), 2)\n",
    "        email_opens = np.random.randint(0, 8)\n",
    "        form_submissions = np.random.randint(0, 3)\n",
    "        ad_impressions = np.random.randint(20, 100)\n",
    "\n",
    "        # conversion probability (linked to acv + engagement)\n",
    "        score = (\n",
    "            0.5 * (acv / 100000) + 0.4 * engagement_score + 0.3 * (crm_tier == \"Gold\") - 0.3 * (renewal_status == \"Churned\")\n",
    "        )\n",
    "        prob = np.clip(1 / (1 + np.exp(-3 * (score - 0.5))), 0, 1)\n",
    "        converted = np.random.binomial(1, prob)\n",
    "\n",
    "        rows.append([\n",
    "            f\"L{i+2000}\", account_id, account_domain, nag, geo, country, product,\n",
    "            persona, domain_type, page_visits, clicks, session_duration, evt,\n",
    "            email_opens, form_submissions, ad_impressions, industry, company_size,\n",
    "            annual_revenue, acv, num_licenses, num_products_owned, products_purchased,\n",
    "            license_term, online, billing_term, offering, sap_line, crm_tier,\n",
    "            account_age, engagement_score, tickets, renewal_status, converted\n",
    "        ])\n",
    "\n",
    "    cols = [\"lead_id\", \"account_id\", \"account_domain\", \"nag_region\", \"geo_region\", \"country\",\n",
    "            \"product_interest\", \"persona_audience_role\", \"domain_type\", \"page_visits\", \"clicks\",\n",
    "            \"avg_session_duration\", \"evt_event_type\", \"email_opens\", \"form_submissions\", \"ad_impressions\",\n",
    "            \"industry\", \"company_size\", \"annual_revenue\", \"acv\", \"num_licenses\", \"num_products_owned\",\n",
    "            \"products_already_purchased\", \"license_term\", \"online_or_offline\", \"billing_term_subgroup\",\n",
    "            \"offering_subcategory\", \"sap_product_line\", \"crm_tier\", \"account_age_months\",\n",
    "            \"avg_monthly_engagement_score\", \"support_tickets_last_6mo\", \"renewal_status\", \"converted\"]\n",
    "\n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de7e5f-6e95-46bb-b708-72bb69eb070c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3117f4-ed08-4656-88c8-9099b8a9c7f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 sample:\n",
      "  lead_id     geo_region country product_interest persona_audience_role  \\\n",
      "0   L1000  North America     USA       Fusion 360             Architect   \n",
      "1   L1001  North America     USA         Inventor            Contractor   \n",
      "2   L1002  North America     USA            Revit               Student   \n",
      "3   L1003          LATAM  Brazil         Civil 3D               Student   \n",
      "4   L1004           EMEA  France         Civil 3D              Designer   \n",
      "\n",
      "  domain_type  page_visits  clicks  avg_session_duration evt_event_type  \\\n",
      "0        .org            6       3                  1.92    Email_Click   \n",
      "1        .com            8       2                  1.97     Page_Visit   \n",
      "2        .com            4       2                  3.63    Email_Click   \n",
      "3        .net            7       7                  2.87     Page_Visit   \n",
      "4        .net            6       4                  1.66    Email_Click   \n",
      "\n",
      "   email_opens  form_submissions  ad_impressions  converted  \n",
      "0            4                 0              67          0  \n",
      "1            2                 2              30          1  \n",
      "2            2                 1              45          0  \n",
      "3            4                 1              69          1  \n",
      "4            0                 1              42          1  \n",
      "\n",
      "Group 2 sample:\n",
      "  lead_id account_id    account_domain nag_region     geo_region  country  \\\n",
      "0   L2000      A3000    inventor-0.com       EMEA           EMEA       UK   \n",
      "1   L2001      A3001    civil 3d-1.com       EMEA           EMEA   Brazil   \n",
      "2   L2002      A3002    inventor-2.com      NAMER  North America   Canada   \n",
      "3   L2003      A3003  fusion 360-3.com       APAC           APAC  Germany   \n",
      "4   L2004      A3004       revit-4.com       APAC           APAC    India   \n",
      "\n",
      "  product_interest persona_audience_role domain_type  page_visits  ...  \\\n",
      "0         Inventor              Designer        .com            9  ...   \n",
      "1         Civil 3D            Contractor        .net           17  ...   \n",
      "2         Inventor              Designer        .edu            8  ...   \n",
      "3       Fusion 360               Student        .com           10  ...   \n",
      "4            Revit              Engineer        .com            6  ...   \n",
      "\n",
      "   online_or_offline  billing_term_subgroup  offering_subcategory  \\\n",
      "0            Offline                Monthly  Product Subscription   \n",
      "1            Offline                Monthly           Maintenance   \n",
      "2             Online                Monthly           Maintenance   \n",
      "3             Online            Annual - 1Y           Maintenance   \n",
      "4             Online            Annual - 1Y  Product Subscription   \n",
      "\n",
      "   sap_product_line  crm_tier  account_age_months  \\\n",
      "0               D&M    Silver                  62   \n",
      "1               D&M    Bronze                  11   \n",
      "2               M&E    Bronze                  50   \n",
      "3               D&M    Silver                  58   \n",
      "4               M&E    Bronze                  69   \n",
      "\n",
      "  avg_monthly_engagement_score  support_tickets_last_6mo  renewal_status  \\\n",
      "0                     0.661180                         2         Expired   \n",
      "1                     0.017639                         3         Expired   \n",
      "2                     0.406926                         0         Expired   \n",
      "3                     1.000000                         4          Active   \n",
      "4                     0.618500                         3          Active   \n",
      "\n",
      "   converted  \n",
      "0          1  \n",
      "1          0  \n",
      "2          1  \n",
      "3          0  \n",
      "4          0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "group1 = generate_group1_data(1000)\n",
    "group2 = generate_group2_data(1000)\n",
    "\n",
    "print(\"Group 1 sample:\")\n",
    "# print(group1.head())\n",
    "\n",
    "print(\"\\nGroup 2 sample:\")\n",
    "print(group2.head())\n",
    "\n",
    "# Save to CSV if needed\n",
    "group1.to_csv(\"group1_coldstart_leads.csv\", index=False)\n",
    "group2.to_csv(\"group2_account_leads.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1095ce5-49a1-43f5-b11e-36ddba40fa99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7e670f-b564-4b82-9b37-9bca25a3339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>country</th>\n",
       "      <th>product_interest</th>\n",
       "      <th>persona_audience_role</th>\n",
       "      <th>domain_type</th>\n",
       "      <th>page_visits</th>\n",
       "      <th>clicks</th>\n",
       "      <th>avg_session_duration</th>\n",
       "      <th>evt_event_type</th>\n",
       "      <th>email_opens</th>\n",
       "      <th>form_submissions</th>\n",
       "      <th>ad_impressions</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1000</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Fusion 360</td>\n",
       "      <td>Architect</td>\n",
       "      <td>.org</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.92</td>\n",
       "      <td>Email_Click</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1001</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Inventor</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>.com</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Page_Visit</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1002</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Revit</td>\n",
       "      <td>Student</td>\n",
       "      <td>.com</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.63</td>\n",
       "      <td>Email_Click</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L1003</td>\n",
       "      <td>LATAM</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Civil 3D</td>\n",
       "      <td>Student</td>\n",
       "      <td>.net</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2.87</td>\n",
       "      <td>Page_Visit</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L1004</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>France</td>\n",
       "      <td>Civil 3D</td>\n",
       "      <td>Designer</td>\n",
       "      <td>.net</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Email_Click</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lead_id     geo_region country product_interest persona_audience_role  \\\n",
       "0   L1000  North America     USA       Fusion 360             Architect   \n",
       "1   L1001  North America     USA         Inventor            Contractor   \n",
       "2   L1002  North America     USA            Revit               Student   \n",
       "3   L1003          LATAM  Brazil         Civil 3D               Student   \n",
       "4   L1004           EMEA  France         Civil 3D              Designer   \n",
       "\n",
       "  domain_type  page_visits  clicks  avg_session_duration evt_event_type  \\\n",
       "0        .org            6       3                  1.92    Email_Click   \n",
       "1        .com            8       2                  1.97     Page_Visit   \n",
       "2        .com            4       2                  3.63    Email_Click   \n",
       "3        .net            7       7                  2.87     Page_Visit   \n",
       "4        .net            6       4                  1.66    Email_Click   \n",
       "\n",
       "   email_opens  form_submissions  ad_impressions  converted  \n",
       "0            4                 0              67          0  \n",
       "1            2                 2              30          1  \n",
       "2            2                 1              45          0  \n",
       "3            4                 1              69          1  \n",
       "4            0                 1              42          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4598e45b-2c92-4833-9d9b-2c2e8990833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_domain</th>\n",
       "      <th>nag_region</th>\n",
       "      <th>geo_region</th>\n",
       "      <th>country</th>\n",
       "      <th>product_interest</th>\n",
       "      <th>persona_audience_role</th>\n",
       "      <th>domain_type</th>\n",
       "      <th>page_visits</th>\n",
       "      <th>...</th>\n",
       "      <th>online_or_offline</th>\n",
       "      <th>billing_term_subgroup</th>\n",
       "      <th>offering_subcategory</th>\n",
       "      <th>sap_product_line</th>\n",
       "      <th>crm_tier</th>\n",
       "      <th>account_age_months</th>\n",
       "      <th>avg_monthly_engagement_score</th>\n",
       "      <th>support_tickets_last_6mo</th>\n",
       "      <th>renewal_status</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2000</td>\n",
       "      <td>A3000</td>\n",
       "      <td>inventor-0.com</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>UK</td>\n",
       "      <td>Inventor</td>\n",
       "      <td>Designer</td>\n",
       "      <td>.com</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Product Subscription</td>\n",
       "      <td>D&amp;M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>62</td>\n",
       "      <td>0.661180</td>\n",
       "      <td>2</td>\n",
       "      <td>Expired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L2001</td>\n",
       "      <td>A3001</td>\n",
       "      <td>civil 3d-1.com</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>EMEA</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Civil 3D</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>.net</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>D&amp;M</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>11</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>3</td>\n",
       "      <td>Expired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L2002</td>\n",
       "      <td>A3002</td>\n",
       "      <td>inventor-2.com</td>\n",
       "      <td>NAMER</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Inventor</td>\n",
       "      <td>Designer</td>\n",
       "      <td>.edu</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Online</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>M&amp;E</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>50</td>\n",
       "      <td>0.406926</td>\n",
       "      <td>0</td>\n",
       "      <td>Expired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L2003</td>\n",
       "      <td>A3003</td>\n",
       "      <td>fusion 360-3.com</td>\n",
       "      <td>APAC</td>\n",
       "      <td>APAC</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Fusion 360</td>\n",
       "      <td>Student</td>\n",
       "      <td>.com</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>Online</td>\n",
       "      <td>Annual - 1Y</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>D&amp;M</td>\n",
       "      <td>Silver</td>\n",
       "      <td>58</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L2004</td>\n",
       "      <td>A3004</td>\n",
       "      <td>revit-4.com</td>\n",
       "      <td>APAC</td>\n",
       "      <td>APAC</td>\n",
       "      <td>India</td>\n",
       "      <td>Revit</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>.com</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>Online</td>\n",
       "      <td>Annual - 1Y</td>\n",
       "      <td>Product Subscription</td>\n",
       "      <td>M&amp;E</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>69</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>3</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  lead_id account_id    account_domain nag_region     geo_region  country  \\\n",
       "0   L2000      A3000    inventor-0.com       EMEA           EMEA       UK   \n",
       "1   L2001      A3001    civil 3d-1.com       EMEA           EMEA   Brazil   \n",
       "2   L2002      A3002    inventor-2.com      NAMER  North America   Canada   \n",
       "3   L2003      A3003  fusion 360-3.com       APAC           APAC  Germany   \n",
       "4   L2004      A3004       revit-4.com       APAC           APAC    India   \n",
       "\n",
       "  product_interest persona_audience_role domain_type  page_visits  ...  \\\n",
       "0         Inventor              Designer        .com            9  ...   \n",
       "1         Civil 3D            Contractor        .net           17  ...   \n",
       "2         Inventor              Designer        .edu            8  ...   \n",
       "3       Fusion 360               Student        .com           10  ...   \n",
       "4            Revit              Engineer        .com            6  ...   \n",
       "\n",
       "   online_or_offline  billing_term_subgroup  offering_subcategory  \\\n",
       "0            Offline                Monthly  Product Subscription   \n",
       "1            Offline                Monthly           Maintenance   \n",
       "2             Online                Monthly           Maintenance   \n",
       "3             Online            Annual - 1Y           Maintenance   \n",
       "4             Online            Annual - 1Y  Product Subscription   \n",
       "\n",
       "   sap_product_line  crm_tier  account_age_months  \\\n",
       "0               D&M    Silver                  62   \n",
       "1               D&M    Bronze                  11   \n",
       "2               M&E    Bronze                  50   \n",
       "3               D&M    Silver                  58   \n",
       "4               M&E    Bronze                  69   \n",
       "\n",
       "  avg_monthly_engagement_score  support_tickets_last_6mo  renewal_status  \\\n",
       "0                     0.661180                         2         Expired   \n",
       "1                     0.017639                         3         Expired   \n",
       "2                     0.406926                         0         Expired   \n",
       "3                     1.000000                         4          Active   \n",
       "4                     0.618500                         3          Active   \n",
       "\n",
       "   converted  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbc936-056b-4134-bb9e-351794f75c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e428d-035a-47d2-b578-7df0b40ff5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18cd23-1ccc-4b7e-bd09-f3fd9af8289a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a743180a-05b1-46e8-88e2-9778bc85389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d0c525b-07e3-4873-b75a-8538eaa2e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 meta-training tasks from Group 2\n",
      "✅ Phase 2 complete — leak-safe preprocessing ready for meta-learning.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Phase 2: Feature Engineering & Data Preparation (for Meta-Learning)\n",
    "# ==============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load synthetic datasets\n",
    "# -------------------------------\n",
    "group1 = pd.read_csv(\"group1_coldstart_leads.csv\")\n",
    "group2 = pd.read_csv(\"group2_account_leads.csv\")\n",
    "\n",
    "# Separate target variable early (avoid leakage)\n",
    "y1 = group1.pop(\"converted\")\n",
    "y2 = group2.pop(\"converted\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Split each group separately\n",
    "# -------------------------------\n",
    "def stratified_splits(X, y, seed=42):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=seed\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=seed\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X1_train, X1_val, X1_test, y1_train, y1_val, y1_test = stratified_splits(group1, y1)\n",
    "X2_train, X2_val, X2_test, y2_train, y2_val, y2_test = stratified_splits(group2, y2)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Schema alignment\n",
    "# -------------------------------\n",
    "# Add missing account-level columns to Group 1 as NaN\n",
    "account_features = [\n",
    "    \"industry\", \"company_size\", \"annual_revenue\", \"acv\", \"num_licenses\",\n",
    "    \"num_products_owned\", \"license_term\", \"online_or_offline\",\n",
    "    \"billing_term_subgroup\", \"offering_subcategory\", \"sap_product_line\",\n",
    "    \"crm_tier\", \"account_age_months\", \"avg_monthly_engagement_score\",\n",
    "    \"support_tickets_last_6mo\", \"renewal_status\"\n",
    "]\n",
    "\n",
    "for col in account_features:\n",
    "    if col not in X1_train.columns:\n",
    "        X1_train[col] = np.nan\n",
    "        X1_val[col] = np.nan\n",
    "        X1_test[col] = np.nan\n",
    "\n",
    "# Ensure both groups have identical column order\n",
    "X1_train = X1_train.reindex(columns=sorted(X2_train.columns))\n",
    "X1_val   = X1_val.reindex(columns=sorted(X2_train.columns))\n",
    "X1_test  = X1_test.reindex(columns=sorted(X2_train.columns))\n",
    "X2_train = X2_train.reindex(columns=sorted(X2_train.columns))\n",
    "X2_val   = X2_val.reindex(columns=sorted(X2_train.columns))\n",
    "X2_test  = X2_test.reindex(columns=sorted(X2_train.columns))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Preprocessing pipeline (fit ONLY on Group 2)\n",
    "# -------------------------------\n",
    "categorical_cols = [\n",
    "    \"geo_region\", \"country\", \"product_interest\",\n",
    "    \"persona_audience_role\", \"domain_type\", \"evt_event_type\",\n",
    "    \"industry\", \"license_term\", \"online_or_offline\",\n",
    "    \"billing_term_subgroup\", \"offering_subcategory\",\n",
    "    \"sap_product_line\", \"crm_tier\", \"renewal_status\"\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"page_visits\", \"clicks\", \"avg_session_duration\",\n",
    "    \"email_opens\", \"form_submissions\", \"ad_impressions\",\n",
    "    \"company_size\", \"annual_revenue\", \"acv\", \"num_licenses\",\n",
    "    \"num_products_owned\", \"account_age_months\",\n",
    "    \"avg_monthly_engagement_score\", \"support_tickets_last_6mo\"\n",
    "]\n",
    "\n",
    "# Pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Fit only on Group 2 training data\n",
    "preprocessor.fit(X2_train)\n",
    "\n",
    "# Transform both groups (safe — using fitted object)\n",
    "X2_train_proc = preprocessor.transform(X2_train)\n",
    "X2_val_proc   = preprocessor.transform(X2_val)\n",
    "X2_test_proc  = preprocessor.transform(X2_test)\n",
    "\n",
    "X1_train_proc = preprocessor.transform(X1_train)\n",
    "X1_val_proc   = preprocessor.transform(X1_val)\n",
    "X1_test_proc  = preprocessor.transform(X1_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Build meta-learning tasks from Group 2\n",
    "# -------------------------------\n",
    "# Example: create tasks by product_interest (few-shot style)\n",
    "meta_tasks = []\n",
    "for product in X2_train[\"product_interest\"].unique():\n",
    "    task_mask = X2_train[\"product_interest\"] == product\n",
    "    X_task = X2_train_proc[task_mask]\n",
    "    y_task = y2_train[task_mask]\n",
    "    if len(y_task) > 20:  # ensure enough samples\n",
    "        meta_tasks.append((X_task, y_task))\n",
    "\n",
    "print(f\"Created {len(meta_tasks)} meta-training tasks from Group 2\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Save processed data\n",
    "# -------------------------------\n",
    "joblib.dump({\n",
    "    \"preprocessor\": preprocessor,\n",
    "    \"group2_train\": (X2_train_proc, y2_train),\n",
    "    \"group2_val\":   (X2_val_proc,   y2_val),\n",
    "    \"group2_test\":  (X2_test_proc,  y2_test),\n",
    "    \"group1_train\": (X1_train_proc, y1_train),\n",
    "    \"group1_val\":   (X1_val_proc,   y1_val),\n",
    "    \"group1_test\":  (X1_test_proc,  y1_test),\n",
    "    \"meta_tasks\":   meta_tasks\n",
    "}, \"phase2_processed_data.pkl\")\n",
    "\n",
    "print(\"✅ Phase 2 complete — leak-safe preprocessing ready for meta-learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc77e29-c2e0-4ff9-b2fb-f4fa0e8940fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07d21e-29b9-4330-9acf-ffd9177c1a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e156ca-33c2-4eac-9b07-c4a83257da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552edeb7-0ee3-4881-baf7-7e506c6e4398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaebcac-9ab3-4ddf-adeb-7254ac1d1ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb45b47-abd6-4a2b-9d98-92da28fd150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta-iter 0050] Group2 Val: loss=0.6948 AUC=0.5869\n",
      "[Meta-iter 0100] Group2 Val: loss=0.6946 AUC=0.5905\n",
      "[Meta-iter 0150] Group2 Val: loss=0.6944 AUC=0.5958\n",
      "[Meta-iter 0200] Group2 Val: loss=0.6942 AUC=0.5997\n",
      "[Meta-iter 0250] Group2 Val: loss=0.6940 AUC=0.6038\n",
      "[Meta-iter 0300] Group2 Val: loss=0.6939 AUC=0.6057\n",
      "[Meta-iter 0350] Group2 Val: loss=0.6937 AUC=0.6079\n",
      "[Meta-iter 0400] Group2 Val: loss=0.6935 AUC=0.6094\n",
      "[Meta-iter 0450] Group2 Val: loss=0.6934 AUC=0.6117\n",
      "[Meta-iter 0500] Group2 Val: loss=0.6932 AUC=0.6133\n",
      "[Meta-iter 0550] Group2 Val: loss=0.6930 AUC=0.6137\n",
      "[Meta-iter 0600] Group2 Val: loss=0.6929 AUC=0.6131\n",
      "✅ Meta-training done. Best Group2 Val AUC: 0.6137\n",
      "Group 2 (rich) Test: loss=0.6939 AUC=0.5604\n",
      "Group 1 (cold)  Val:  loss=1.9931 AUC=0.5775\n",
      "Group 1 (cold)  Test: loss=2.6319 AUC=0.4306\n",
      "✅ Phase 3 complete: meta-trained on Group 2, adapted and evaluated on Group 1.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Phase 3: First-Order Meta-Learning (Reptile) in PyTorch\n",
    "# Reptile, a first-order meta-learning algorithm.\n",
    "# Train on Group 2 tasks, adapt to Group 1 (cold-start)\n",
    "# ==============================================\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "# -------------------------------\n",
    "# 0) Repro + Device\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Load processed Phase 2 data\n",
    "#    (These were created in Phase 2)\n",
    "# -------------------------------\n",
    "bundle = joblib.load(\"phase2_processed_data.pkl\")\n",
    "\n",
    "X2_train, y2_train = bundle[\"group2_train\"]\n",
    "X2_val,   y2_val   = bundle[\"group2_val\"]\n",
    "X2_test,  y2_test  = bundle[\"group2_test\"]\n",
    "\n",
    "X1_train, y1_train = bundle[\"group1_train\"]\n",
    "X1_val,   y1_val   = bundle[\"group1_val\"]\n",
    "X1_test,  y1_test  = bundle[\"group1_test\"]\n",
    "\n",
    "# Convert labels to np arrays (if pandas Series)\n",
    "y2_train = np.asarray(y2_train).astype(np.float32)\n",
    "y2_val   = np.asarray(y2_val).astype(np.float32)\n",
    "y2_test  = np.asarray(y2_test).astype(np.float32)\n",
    "\n",
    "y1_train = np.asarray(y1_train).astype(np.float32)\n",
    "y1_val   = np.asarray(y1_val).astype(np.float32)\n",
    "y1_test  = np.asarray(y1_test).astype(np.float32)\n",
    "\n",
    "input_dim = X2_train.shape[1]  # same for both groups after Phase 2\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Torch helpers\n",
    "# -------------------------------\n",
    "def to_tensor(X, y):\n",
    "    X_t = torch.tensor(np.asarray(X), dtype=torch.float32, device=device)\n",
    "    y_t = torch.tensor(np.asarray(y), dtype=torch.float32, device=device).view(-1, 1)\n",
    "    return X_t, y_t\n",
    "\n",
    "# For quick metrics on numpy\n",
    "def np_auc(y_true, y_prob):\n",
    "    # Handle degenerate cases (all one class)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return float(\"nan\")\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Tabular MLP\n",
    "# -------------------------------\n",
    "class TabMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=(256, 128, 64), p=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(p)]\n",
    "            prev = h\n",
    "        layers += [nn.Linear(prev, 1)]  # binary logit\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # logits\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Task Sampler (few-shot)\n",
    "#    We’ll create class-balanced tasks from Group 2.\n",
    "#    Each task has small support and query sets.\n",
    "# -------------------------------\n",
    "@dataclass\n",
    "class TaskBatch:\n",
    "    Xs: torch.Tensor  # [n_tasks, n_support, D]\n",
    "    ys: torch.Tensor  # [n_tasks, n_support, 1]\n",
    "    Xq: torch.Tensor  # [n_tasks, n_query, D]\n",
    "    yq: torch.Tensor  # [n_tasks, n_query, 1]\n",
    "\n",
    "def sample_task_batch(\n",
    "    X, y,\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,\n",
    "    k_query_per_class=16,\n",
    "    pos_label=1.0,\n",
    "    neg_label=0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Build n_tasks tasks from (X, y).\n",
    "    Each task is class-balanced with K support and Q query per class.\n",
    "    Sampling is with replacement if needed (handles imbalance).\n",
    "    \"\"\"\n",
    "    X = np.asarray(X); y = np.asarray(y)\n",
    "    idx_pos = np.where(y == pos_label)[0]\n",
    "    idx_neg = np.where(y == neg_label)[0]\n",
    "\n",
    "    # Safety: if a class is empty, fallback to random split\n",
    "    if len(idx_pos) == 0 or len(idx_neg) == 0:\n",
    "        idx_all = np.arange(len(y))\n",
    "        tasks_Xs, tasks_ys, tasks_Xq, tasks_yq = [], [], [], []\n",
    "        for _ in range(n_tasks):\n",
    "            chosen = np.random.choice(idx_all, size=(k_support_per_class+k_query_per_class)*2, replace=True)\n",
    "            Xs = X[chosen[:2*k_support_per_class]]\n",
    "            ys = y[chosen[:2*k_support_per_class]][:, None]\n",
    "            Xq = X[chosen[2*k_support_per_class:]]\n",
    "            yq = y[chosen[2*k_support_per_class:]][:, None]\n",
    "            tasks_Xs.append(Xs); tasks_ys.append(ys); tasks_Xq.append(Xq); tasks_yq.append(yq)\n",
    "    else:\n",
    "        tasks_Xs, tasks_ys, tasks_Xq, tasks_yq = [], [], [], []\n",
    "        for _ in range(n_tasks):\n",
    "            sup_pos = np.random.choice(idx_pos, size=k_support_per_class, replace=True)\n",
    "            sup_neg = np.random.choice(idx_neg, size=k_support_per_class, replace=True)\n",
    "            qry_pos = np.random.choice(idx_pos, size=k_query_per_class, replace=True)\n",
    "            qry_neg = np.random.choice(idx_neg, size=k_query_per_class, replace=True)\n",
    "\n",
    "            Xs = np.vstack([X[sup_pos], X[sup_neg]])\n",
    "            ys = np.concatenate([np.ones(k_support_per_class), np.zeros(k_support_per_class)])[:, None]\n",
    "            Xq = np.vstack([X[qry_pos], X[qry_neg]])\n",
    "            yq = np.concatenate([np.ones(k_query_per_class), np.zeros(k_query_per_class)])[:, None]\n",
    "\n",
    "            # Shuffle inside task\n",
    "            s_idx = np.random.permutation(Xs.shape[0])\n",
    "            q_idx = np.random.permutation(Xq.shape[0])\n",
    "            Xs, ys = Xs[s_idx], ys[s_idx]\n",
    "            Xq, yq = Xq[q_idx], yq[q_idx]\n",
    "\n",
    "            tasks_Xs.append(Xs); tasks_ys.append(ys); tasks_Xq.append(Xq); tasks_yq.append(yq)\n",
    "\n",
    "    # Stack to tensors\n",
    "    Xs = torch.tensor(np.stack(tasks_Xs), dtype=torch.float32, device=device)\n",
    "    ys = torch.tensor(np.stack(tasks_ys), dtype=torch.float32, device=device)\n",
    "    Xq = torch.tensor(np.stack(tasks_Xq), dtype=torch.float32, device=device)\n",
    "    yq = torch.tensor(np.stack(tasks_yq), dtype=torch.float32, device=device)\n",
    "\n",
    "    return TaskBatch(Xs, ys, Xq, yq)\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Parameter utilities for Reptile\n",
    "# -------------------------------\n",
    "def get_param_vector(model):\n",
    "    return torch.cat([p.detach().flatten() for p in model.parameters()])\n",
    "\n",
    "def set_param_vector_(model, vec):\n",
    "    idx = 0\n",
    "    for p in model.parameters():\n",
    "        n = p.numel()\n",
    "        p.data.copy_(vec[idx: idx+n].view_as(p))\n",
    "        idx += n\n",
    "\n",
    "def clone_param_vector(model):\n",
    "    return torch.cat([p.detach().clone().flatten() for p in model.parameters()])\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Inner loop: train a *copy* of the model on a single task (support set)\n",
    "# -------------------------------\n",
    "def inner_train_one_task(model, Xs, ys, inner_steps=5, inner_lr=1e-2):\n",
    "    \"\"\"\n",
    "    Returns parameter vector AFTER adapting on the task's support set.\n",
    "    \"\"\"\n",
    "    # Clone model params\n",
    "    theta = clone_param_vector(model)\n",
    "    temp_model = TabMLP(input_dim).to(device)\n",
    "    set_param_vector_(temp_model, theta)\n",
    "\n",
    "    opt = torch.optim.SGD(temp_model.parameters(), lr=inner_lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for _ in range(inner_steps):\n",
    "        opt.zero_grad()\n",
    "        logits = temp_model(Xs)\n",
    "        loss = loss_fn(logits, ys)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return get_param_vector(temp_model)  # θ' (adapted)\n",
    "\n",
    "# -------------------------------\n",
    "# 7) Meta-training loop (Reptile)\n",
    "# -------------------------------\n",
    "def evaluate_numpy(model, X_np, y_np, batch=4096):\n",
    "    \"\"\"Fast eval on a numpy split.\"\"\"\n",
    "    model.eval()\n",
    "    n = len(y_np)\n",
    "    probs = []\n",
    "    loss_fn = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, n, batch):\n",
    "            Xb = torch.tensor(X_np[i:i+batch], dtype=torch.float32, device=device)\n",
    "            yb = torch.tensor(y_np[i:i+batch][:, None], dtype=torch.float32, device=device)\n",
    "            logit = model(Xb)\n",
    "            total_loss += loss_fn(logit, yb).item()\n",
    "            probs.append(torch.sigmoid(logit).squeeze(1).cpu().numpy())\n",
    "    probs = np.concatenate(probs)\n",
    "    return total_loss / n, np_auc(y_np, probs)\n",
    "\n",
    "def reptile_meta_train(\n",
    "    X_train_np, y_train_np,\n",
    "    X_val_np,   y_val_np,\n",
    "    input_dim,\n",
    "    meta_iters=1000,\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,\n",
    "    k_query_per_class=16,\n",
    "    inner_steps=5,\n",
    "    inner_lr=1e-2,\n",
    "    meta_lr=1e-1,\n",
    "    eval_every=50\n",
    "):\n",
    "    model = TabMLP(input_dim).to(device)\n",
    "    base_theta = get_param_vector(model)\n",
    "\n",
    "    best_val_auc = -np.inf\n",
    "    best_state = clone_param_vector(model)\n",
    "\n",
    "    for it in range(1, meta_iters + 1):\n",
    "        # Sample a batch of tasks\n",
    "        tasks = sample_task_batch(\n",
    "            X_train_np, y_train_np,\n",
    "            n_tasks=n_tasks,\n",
    "            k_support_per_class=k_support_per_class,\n",
    "            k_query_per_class=k_query_per_class\n",
    "        )\n",
    "\n",
    "        # For monitoring: compute query loss with the current model (optional)\n",
    "        # Not needed for Reptile update, but useful for sanity checks.\n",
    "\n",
    "        # Inner-loop: adapt on each task support -> collect adapted params\n",
    "        adapted_thetas = []\n",
    "        for t in range(n_tasks):\n",
    "            Xs = tasks.Xs[t]  # [2*k_support, D]\n",
    "            ys = tasks.ys[t]  # [2*k_support, 1]\n",
    "            theta_prime = inner_train_one_task(model, Xs, ys, inner_steps=inner_steps, inner_lr=inner_lr)\n",
    "            adapted_thetas.append(theta_prime)\n",
    "\n",
    "        # Average adapted params over tasks\n",
    "        avg_theta_prime = torch.stack(adapted_thetas, dim=0).mean(dim=0)\n",
    "\n",
    "        # Reptile meta-update: move base params towards avg adapted params\n",
    "        with torch.no_grad():\n",
    "            base_theta = base_theta + meta_lr * (avg_theta_prime - base_theta)\n",
    "            set_param_vector_(model, base_theta)\n",
    "\n",
    "        # Periodic validation on Group 2 (to monitor training)\n",
    "        if it % eval_every == 0:\n",
    "            val_loss, val_auc = evaluate_numpy(model, X_val_np, y_val_np)\n",
    "            print(f\"[Meta-iter {it:04d}] Group2 Val: loss={val_loss:.4f} AUC={val_auc:.4f}\")\n",
    "            if val_auc > best_val_auc:\n",
    "                best_val_auc = val_auc\n",
    "                best_state = clone_param_vector(model)\n",
    "\n",
    "    # Load best meta-params\n",
    "    set_param_vector_(model, best_state)\n",
    "    print(f\"✅ Meta-training done. Best Group2 Val AUC: {best_val_auc:.4f}\")\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# 8) Run meta-training on Group 2\n",
    "# -------------------------------\n",
    "meta_model = reptile_meta_train(\n",
    "    X2_train, y2_train,\n",
    "    X2_val,   y2_val,\n",
    "    input_dim=input_dim,\n",
    "    meta_iters=600,            # tune (e.g., 600–1500)\n",
    "    n_tasks=8,                 # number of tasks per meta-iteration\n",
    "    k_support_per_class=8,     # K-shot\n",
    "    k_query_per_class=16,      # for task sampling; used mainly for sanity checks\n",
    "    inner_steps=5,             # inner adaptation steps\n",
    "    inner_lr=1e-2,             # inner loop lr\n",
    "    meta_lr=5e-2,              # meta step size (towards adapted params)\n",
    "    eval_every=50\n",
    ")\n",
    "\n",
    "# Quick check on Group 2 test (not the main goal, but helpful)\n",
    "g2_test_loss, g2_test_auc = evaluate_numpy(meta_model, X2_test, y2_test)\n",
    "print(f\"Group 2 (rich) Test: loss={g2_test_loss:.4f} AUC={g2_test_auc:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9) Adaptation on Group 1 (cold-start)\n",
    "#    Few-shot fine-tune (freeze some layers if you like).\n",
    "# -------------------------------\n",
    "def adapt_to_group1(\n",
    "    meta_model,\n",
    "    X1_train_np, y1_train_np,\n",
    "    X1_val_np,   y1_val_np,\n",
    "    shots_per_class=32,\n",
    "    steps=50,\n",
    "    lr=1e-3,\n",
    "    freeze_until=None  # e.g., 0, 2 to freeze early layers (optional)\n",
    "):\n",
    "    # Build a small, class-balanced support set from Group 1 train\n",
    "    y = np.asarray(y1_train_np)\n",
    "    pos_idx = np.where(y == 1.0)[0]\n",
    "    neg_idx = np.where(y == 0.0)[0]\n",
    "\n",
    "    sup_pos = np.random.choice(pos_idx, size=shots_per_class, replace=True if len(pos_idx) < shots_per_class else False)\n",
    "    sup_neg = np.random.choice(neg_idx, size=shots_per_class, replace=True if len(neg_idx) < shots_per_class else False)\n",
    "\n",
    "    X_sup = np.vstack([X1_train_np[sup_pos], X1_train_np[sup_neg]])\n",
    "    y_sup = np.concatenate([np.ones(shots_per_class), np.zeros(shots_per_class)])[:, None]\n",
    "\n",
    "    # Shuffle support\n",
    "    idx = np.random.permutation(len(y_sup))\n",
    "    X_sup, y_sup = X_sup[idx], y_sup[idx]\n",
    "\n",
    "    # Clone a working copy of the meta-model\n",
    "    model = TabMLP(input_dim).to(device)\n",
    "    set_param_vector_(model, get_param_vector(meta_model))\n",
    "\n",
    "    # (Optional) freeze early layers\n",
    "    if freeze_until is not None:\n",
    "        depth = 0\n",
    "        for m in model.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if depth < freeze_until:\n",
    "                    for p in m.parameters():\n",
    "                        p.requires_grad = False\n",
    "                depth += 1\n",
    "\n",
    "    opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    X_sup_t = torch.tensor(X_sup, dtype=torch.float32, device=device)\n",
    "    y_sup_t = torch.tensor(y_sup, dtype=torch.float32, device=device)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        logits = model(X_sup_t)\n",
    "        loss = loss_fn(logits, y_sup_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Evaluate on Group 1 val/test\n",
    "    val_loss, val_auc = evaluate_numpy(model, X1_val_np, y1_val_np)\n",
    "    test_loss, test_auc = evaluate_numpy(model, X1_test_np, y1_test_np)\n",
    "    return model, (val_loss, val_auc), (test_loss, test_auc)\n",
    "\n",
    "# Prepare Group 1 numpy splits for adaptation/eval\n",
    "X1_test_np, y1_test_np = X1_test, y1_test  # alias for clarity\n",
    "\n",
    "adapted_model, (g1_val_loss, g1_val_auc), (g1_test_loss, g1_test_auc) = adapt_to_group1(\n",
    "    meta_model,\n",
    "    X1_train, y1_train,\n",
    "    X1_val,   y1_val,\n",
    "    shots_per_class=32,   # tune: 8–64 depending on how \"few-shot\" you want\n",
    "    steps=100,            # tune adaptation length\n",
    "    lr=1e-3,              # adaptation LR\n",
    "    freeze_until=1        # freeze the first Linear layer (optional; try None/0/1/2)\n",
    ")\n",
    "\n",
    "print(f\"Group 1 (cold)  Val:  loss={g1_val_loss:.4f} AUC={g1_val_auc:.4f}\")\n",
    "print(f\"Group 1 (cold)  Test: loss={g1_test_loss:.4f} AUC={g1_test_auc:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 10) Save adapted model (optional)\n",
    "# -------------------------------\n",
    "torch.save({\n",
    "    \"state_dict\": adapted_model.state_dict(),\n",
    "    \"input_dim\": input_dim\n",
    "}, \"meta_adapted_group1.pt\")\n",
    "\n",
    "print(\"✅ Phase 3 complete: meta-trained on Group 2, adapted and evaluated on Group 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b7006-38b9-4527-b6ec-4838261f2942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ad73fe4-5b6a-43be-9d6d-655b87c44de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Feature                      | **MAML (2nd order)**   | **FOMAML**                              | **Reptile**                      |\n",
    "# | ---------------------------- | ---------------------- | --------------------------------------- | -------------------------------- |\n",
    "# | Uses 2nd-order derivatives?  | ✅ Yes                  | ❌ No                                    | ❌ No                             |\n",
    "# | Backprop through inner loop? | ✅ Yes                  | ❌ No                                    | ❌ No                             |\n",
    "# | Memory/Compute cost          | High                   | Medium                                  | **Low**                          |\n",
    "# | Update formula               | Gradient of query loss | Gradient of query loss (1st order only) | Move toward task-adapted weights |\n",
    "# | Typical performance          | Slightly better        | Similar                                 | **Very close**                   |\n",
    "# | Implementation simplicity    | Complex                | Easier                                  | **Simplest**                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95910b2-456f-44c7-84e4-2f13209e84d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f80d37-3a72-47cb-94b3-9384548e4d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d410439-04f2-4239-8b19-89111022c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################\n",
    "\n",
    "# Phase 3 — FOMAML in pure PyTorch (no extra libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdb181-53ad-476a-bdb3-cd0d7a0c3d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f6cf93-32b2-4347-ac62-a1adcdd25f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta 0050] Group2 Val: loss=1.9778 AUC=0.6371\n",
      "[Meta 0100] Group2 Val: loss=2.8497 AUC=0.6166\n",
      "[Meta 0150] Group2 Val: loss=2.7317 AUC=0.6114\n",
      "[Meta 0200] Group2 Val: loss=3.4063 AUC=0.6146\n",
      "[Meta 0250] Group2 Val: loss=3.1915 AUC=0.6152\n",
      "[Meta 0300] Group2 Val: loss=2.9628 AUC=0.6285\n",
      "[Meta 0350] Group2 Val: loss=3.3661 AUC=0.5990\n",
      "[Meta 0400] Group2 Val: loss=3.3795 AUC=0.5837\n",
      "[Meta 0450] Group2 Val: loss=3.6664 AUC=0.6069\n",
      "[Meta 0500] Group2 Val: loss=3.0220 AUC=0.6497\n",
      "[Meta 0550] Group2 Val: loss=3.1295 AUC=0.6075\n",
      "[Meta 0600] Group2 Val: loss=3.4523 AUC=0.5884\n",
      "[Meta 0650] Group2 Val: loss=3.2111 AUC=0.6124\n",
      "[Meta 0700] Group2 Val: loss=3.2615 AUC=0.6358\n",
      "[Meta 0750] Group2 Val: loss=3.2653 AUC=0.6435\n",
      "[Meta 0800] Group2 Val: loss=3.1643 AUC=0.6322\n",
      "✅ Meta-training done. Best Group2 Val AUC: 0.6497\n",
      "Group 2 Test: loss=2.8610 AUC=0.6614\n",
      "Group 1 Val : loss=0.8962 AUC=0.5091\n",
      "Group 1 Test: loss=0.9330 AUC=0.5058\n",
      "✅ Phase 3 complete: FOMAML meta-trained on Group 2, adapted to Group 1.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Phase 3: FOMAML (First-Order MAML) in vanilla PyTorch\n",
    "# Train on Group 2 tasks, adapt to Group 1 (cold-start)\n",
    "# ==============================================\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# -------------------------------\n",
    "# 0) Repro + Device\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Load processed Phase 2 data\n",
    "# -------------------------------\n",
    "bundle = joblib.load(\"phase2_processed_data.pkl\")\n",
    "\n",
    "X2_train, y2_train = bundle[\"group2_train\"]\n",
    "X2_val,   y2_val   = bundle[\"group2_val\"]\n",
    "X2_test,  y2_test  = bundle[\"group2_test\"]\n",
    "\n",
    "X1_train, y1_train = bundle[\"group1_train\"]\n",
    "X1_val,   y1_val   = bundle[\"group1_val\"]\n",
    "X1_test,  y1_test  = bundle[\"group1_test\"]\n",
    "\n",
    "# ensure numpy float32\n",
    "def as_xy(X, y):\n",
    "    return np.asarray(X, dtype=np.float32), np.asarray(y, dtype=np.float32)\n",
    "\n",
    "X2_train, y2_train = as_xy(X2_train, y2_train)\n",
    "X2_val,   y2_val   = as_xy(X2_val, y2_val)\n",
    "X2_test,  y2_test  = as_xy(X2_test, y2_test)\n",
    "\n",
    "X1_train, y1_train = as_xy(X1_train, y1_train)\n",
    "X1_val,   y1_val   = as_xy(X1_val, y1_val)\n",
    "X1_test,  y1_test  = as_xy(X1_test, y1_test)\n",
    "\n",
    "input_dim = X2_train.shape[1]\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Model: simple tabular MLP\n",
    "# -------------------------------\n",
    "class TabMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=(256, 128, 64), dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, 1)]  # binary logit\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Helpers\n",
    "# -------------------------------\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def to_tensor(X, y=None):\n",
    "    X_t = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    if y is None:\n",
    "        return X_t\n",
    "    y_t = torch.tensor(y.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "    return X_t, y_t\n",
    "\n",
    "def np_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return float(\"nan\")\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_numpy(model, X_np, y_np, batch=4096):\n",
    "    model.eval()\n",
    "    n = len(y_np)\n",
    "    total_loss, probs = 0.0, []\n",
    "    for i in range(0, n, batch):\n",
    "        Xb = to_tensor(X_np[i:i+batch])\n",
    "        yb = torch.tensor(y_np[i:i+batch].reshape(-1,1), dtype=torch.float32, device=device)\n",
    "        logit = model(Xb)\n",
    "        total_loss += bce(logit, yb).item() * len(yb)\n",
    "        probs.append(torch.sigmoid(logit).squeeze(1).cpu().numpy())\n",
    "    probs = np.concatenate(probs)\n",
    "    return total_loss / n, np_auc(y_np, probs)\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Task sampler (balanced few-shot)\n",
    "# -------------------------------\n",
    "def sample_task_batch(\n",
    "    X, y,\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,\n",
    "    k_query_per_class=16\n",
    "):\n",
    "    X = np.asarray(X); y = np.asarray(y)\n",
    "    idx_pos = np.where(y == 1.0)[0]\n",
    "    idx_neg = np.where(y == 0.0)[0]\n",
    "\n",
    "    tasks = []\n",
    "    for _ in range(n_tasks):\n",
    "        # sample support\n",
    "        sp = np.random.choice(idx_pos, k_support_per_class, replace=(len(idx_pos) < k_support_per_class))\n",
    "        sn = np.random.choice(idx_neg, k_support_per_class, replace=(len(idx_neg) < k_support_per_class))\n",
    "        Xs = np.vstack([X[sp], X[sn]])\n",
    "        ys = np.concatenate([np.ones(k_support_per_class), np.zeros(k_support_per_class)])\n",
    "\n",
    "        # sample query\n",
    "        qp = np.random.choice(idx_pos, k_query_per_class, replace=(len(idx_pos) < k_query_per_class))\n",
    "        qn = np.random.choice(idx_neg, k_query_per_class, replace=(len(idx_neg) < k_query_per_class))\n",
    "        Xq = np.vstack([X[qp], X[qn]])\n",
    "        yq = np.concatenate([np.ones(k_query_per_class), np.zeros(k_query_per_class)])\n",
    "\n",
    "        # shuffle inside each split\n",
    "        s_idx = np.random.permutation(len(ys))\n",
    "        q_idx = np.random.permutation(len(yq))\n",
    "        tasks.append((\n",
    "            Xs[s_idx].astype(np.float32), ys[s_idx].astype(np.float32),\n",
    "            Xq[q_idx].astype(np.float32), yq[q_idx].astype(np.float32)\n",
    "        ))\n",
    "    return tasks\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Inner loop (task adaptation) on support\n",
    "# -------------------------------\n",
    "def inner_adapt(model, Xs, ys, steps=5, lr=1e-2):\n",
    "    \"\"\"Adapt a CLONED model on support set; return the adapted model.\"\"\"\n",
    "    adapted = copy.deepcopy(model)\n",
    "    opt = torch.optim.SGD(adapted.parameters(), lr=lr)\n",
    "    Xs_t, ys_t = to_tensor(Xs, ys)\n",
    "    adapted.train()\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        logits = adapted(Xs_t)\n",
    "        loss = bce(logits, ys_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return adapted\n",
    "\n",
    "# -------------------------------\n",
    "# 6) FOMAML meta-train loop\n",
    "# -------------------------------\n",
    "def fomaml_meta_train(\n",
    "    X2_tr, y2_tr, X2_val, y2_val,\n",
    "    input_dim,\n",
    "    meta_iters=800,\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,\n",
    "    k_query_per_class=16,\n",
    "    inner_steps=5,\n",
    "    inner_lr=1e-2,\n",
    "    meta_lr=5e-3,\n",
    "    weight_decay=1e-4,\n",
    "    eval_every=50\n",
    "):\n",
    "    base = TabMLP(input_dim).to(device)\n",
    "    meta_opt = torch.optim.Adam(base.parameters(), lr=meta_lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_auc = -np.inf\n",
    "    best_state = copy.deepcopy(base.state_dict())\n",
    "\n",
    "    for it in range(1, meta_iters+1):\n",
    "        base.zero_grad()\n",
    "        tasks = sample_task_batch(\n",
    "            X2_tr, y2_tr,\n",
    "            n_tasks=n_tasks,\n",
    "            k_support_per_class=k_support_per_class,\n",
    "            k_query_per_class=k_query_per_class\n",
    "        )\n",
    "\n",
    "        # accumulate first-order grads from each task\n",
    "        total_tasks = 0\n",
    "        for (Xs, ys, Xq, yq) in tasks:\n",
    "            # 1) adapt cloned model on support\n",
    "            adapted = inner_adapt(base, Xs, ys, steps=inner_steps, lr=inner_lr)\n",
    "\n",
    "            # 2) compute query loss & grads wrt ADAPTED params\n",
    "            Xq_t, yq_t = to_tensor(Xq, yq)\n",
    "            adapted.zero_grad()\n",
    "            logits_q = adapted(Xq_t)\n",
    "            loss_q = bce(logits_q, yq_t)\n",
    "            loss_q.backward()\n",
    "\n",
    "            # 3) copy grads from adapted params onto base params (FOMAML)\n",
    "            with torch.no_grad():\n",
    "                for p_base, p_adapt in zip(base.parameters(), adapted.parameters()):\n",
    "                    if p_adapt.grad is not None:\n",
    "                        if p_base.grad is None:\n",
    "                            p_base.grad = p_adapt.grad.detach().clone()\n",
    "                        else:\n",
    "                            p_base.grad.add_(p_adapt.grad.detach())\n",
    "\n",
    "            total_tasks += 1\n",
    "\n",
    "        # 4) average grads across tasks, meta step\n",
    "        if total_tasks > 0:\n",
    "            with torch.no_grad():\n",
    "                for p in base.parameters():\n",
    "                    if p.grad is not None:\n",
    "                        p.grad.div_(total_tasks)\n",
    "\n",
    "        meta_opt.step()\n",
    "\n",
    "        # monitor Group 2 val\n",
    "        if it % eval_every == 0:\n",
    "            val_loss, val_auc = evaluate_numpy(base, X2_val, y2_val)\n",
    "            print(f\"[Meta {it:04d}] Group2 Val: loss={val_loss:.4f} AUC={val_auc:.4f}\")\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_state = copy.deepcopy(base.state_dict())\n",
    "\n",
    "    base.load_state_dict(best_state)\n",
    "    print(f\"✅ Meta-training done. Best Group2 Val AUC: {best_auc:.4f}\")\n",
    "    return base\n",
    "\n",
    "# -------------------------------\n",
    "# 7) Run meta-training on Group 2\n",
    "# -------------------------------\n",
    "meta_model = fomaml_meta_train(\n",
    "    X2_train, y2_train, X2_val, y2_val,\n",
    "    input_dim=input_dim,\n",
    "    meta_iters=800,           # tune 600–1500\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,    # K-shot\n",
    "    k_query_per_class=16,\n",
    "    inner_steps=5,\n",
    "    inner_lr=1e-2,\n",
    "    meta_lr=5e-3,             # small meta LR works well with Adam\n",
    "    weight_decay=1e-4,\n",
    "    eval_every=50\n",
    ")\n",
    "\n",
    "g2_test_loss, g2_test_auc = evaluate_numpy(meta_model, X2_test, y2_test)\n",
    "print(f\"Group 2 Test: loss={g2_test_loss:.4f} AUC={g2_test_auc:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8) Adapt to Group 1 (few-shot) and evaluate\n",
    "# -------------------------------\n",
    "def adapt_to_group1(\n",
    "    base_model,\n",
    "    X1_tr, y1_tr, X1_val, y1_val, X1_test, y1_test,\n",
    "    shots_per_class=32,\n",
    "    steps=100,\n",
    "    lr=1e-3,\n",
    "    freeze_until=1  # freeze first Linear layer; try None/0/1/2\n",
    "):\n",
    "    # build small, class-balanced support from Group 1 train\n",
    "    pos = np.where(y1_tr == 1.0)[0]\n",
    "    neg = np.where(y1_tr == 0.0)[0]\n",
    "    sp = np.random.choice(pos, shots_per_class, replace=(len(pos) < shots_per_class))\n",
    "    sn = np.random.choice(neg, shots_per_class, replace=(len(neg) < shots_per_class))\n",
    "\n",
    "    Xs = np.vstack([X1_tr[sp], X1_tr[sn]]).astype(np.float32)\n",
    "    ys = np.concatenate([np.ones(shots_per_class), np.zeros(shots_per_class)]).astype(np.float32)\n",
    "    idx = np.random.permutation(len(ys)); Xs, ys = Xs[idx], ys[idx]\n",
    "\n",
    "    model = copy.deepcopy(base_model)\n",
    "\n",
    "    # optional freeze\n",
    "    if freeze_until is not None:\n",
    "        depth = 0\n",
    "        for m in model.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if depth < freeze_until:\n",
    "                    for p in m.parameters():\n",
    "                        p.requires_grad = False\n",
    "                depth += 1\n",
    "\n",
    "    opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    Xs_t, ys_t = to_tensor(Xs, ys)\n",
    "    model.train()\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        logits = model(Xs_t)\n",
    "        loss = bce(logits, ys_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # eval\n",
    "    val_loss, val_auc  = evaluate_numpy(model, X1_val,  y1_val)\n",
    "    test_loss, test_auc = evaluate_numpy(model, X1_test, y1_test)\n",
    "    return model, (val_loss, val_auc), (test_loss, test_auc)\n",
    "\n",
    "adapted_model, (g1_val_loss, g1_val_auc), (g1_test_loss, g1_test_auc) = adapt_to_group1(\n",
    "    meta_model,\n",
    "    X1_train, y1_train,\n",
    "    X1_val,   y1_val,\n",
    "    X1_test,  y1_test,\n",
    "    shots_per_class=32,  # try 8,16,32,64\n",
    "    steps=100,\n",
    "    lr=1e-3,\n",
    "    freeze_until=1\n",
    ")\n",
    "\n",
    "print(f\"Group 1 Val : loss={g1_val_loss:.4f} AUC={g1_val_auc:.4f}\")\n",
    "print(f\"Group 1 Test: loss={g1_test_loss:.4f} AUC={g1_test_auc:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9) Save adapted model (optional)\n",
    "# -------------------------------\n",
    "torch.save({\"state_dict\": adapted_model.state_dict(), \"input_dim\": input_dim},\n",
    "           \"fomaml_group1_adapted.pt\")\n",
    "print(\"✅ Phase 3 complete: FOMAML meta-trained on Group 2, adapted to Group 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbee36-4287-4107-aafa-7b9e21928c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tips & knobs to tune\n",
    "\n",
    "# shots_per_class: 8–64. fewer shots = harder; meta-learning helps more.\n",
    "\n",
    "# inner_steps / inner_lr: how aggressively each task adapts.\n",
    "\n",
    "# meta_lr: smaller (e.g., 5e-3) with Adam usually stable.\n",
    "\n",
    "# freeze_until: try None (no freeze) vs 1/2 to curb overfitting on tiny Group 1.\n",
    "\n",
    "# task definition: current sampler is class-balanced random. for extra realism, build tasks by product or geo: precompute masks on raw (preprocessed) splits, then sample within each mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5aa536-e538-4b2a-9815-8645afb12678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a5e687f-f79e-4336-9ff6-553dddcc598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99fbaa-9a60-4f0a-87b6-6c929f5a5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Minimal, pure-PyTorch MAML (second-order) loop\n",
    "# Below is a drop-in replacement for the training loop of Phase 3, using only PyTorch (no higher, no learn2learn). It assumes you already loaded and preprocessed the Phase-2 artifacts (X2_train, y2_train, etc.) and you have the TabMLP model and the sample_task_batch function from earlier.\n",
    "\n",
    "# It uses torch.nn.utils.stateless.functional_call (PyTorch ≥ 2.0) to run the model with adapted parameters without mutating the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b57ec2-99aa-4b58-b72b-014aff022cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.stateless import functional_call\n",
    "\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def model_named_params(model):\n",
    "    # Ordered mapping (name -> Parameter); needed for functional_call\n",
    "    return dict(model.named_parameters())\n",
    "\n",
    "def inner_adapt_second_order(model, Xs, ys, steps=5, inner_lr=1e-2):\n",
    "    \"\"\"\n",
    "    Perform differentiable inner-loop SGD on support set.\n",
    "    Returns a dict of adapted parameter tensors (name -> tensor) that still\n",
    "    carry the computation graph (for second-order meta-gradients).\n",
    "    \"\"\"\n",
    "    params = model_named_params(model)  # references to base params (leaf tensors)\n",
    "    buffers = dict(model.named_buffers())\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # forward with current params\n",
    "        logits = functional_call(model, params, (Xs,), buffers=buffers)\n",
    "        loss = bce(logits, ys)\n",
    "\n",
    "        # compute gradients wrt current params; keep graph for 2nd-order\n",
    "        grads = torch.autograd.grad(loss, params.values(), create_graph=True)\n",
    "\n",
    "        # SGD step: theta' = theta - alpha * grad (produce *new* param tensors)\n",
    "        params = {name: p - inner_lr * g for (name, p), g in zip(params.items(), grads)}\n",
    "\n",
    "    return params  # adapted params with graph intact\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_numpy_functional(model, X_np, y_np, batch=4096):\n",
    "    model.eval()\n",
    "    n = len(y_np)\n",
    "    total_loss, probs = 0.0, []\n",
    "    for i in range(0, n, batch):\n",
    "        Xb = torch.tensor(X_np[i:i+batch], dtype=torch.float32, device=X_np.device if torch.is_tensor(X_np) else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        yb = torch.tensor(y_np[i:i+batch].reshape(-1,1), dtype=torch.float32, device=Xb.device)\n",
    "        logits = model(Xb)  # base evaluation (no adaptation here)\n",
    "        total_loss += bce(logits, yb).item() * len(yb)\n",
    "        probs.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
    "    import numpy as np\n",
    "    probs = np.concatenate(probs)\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc = float(\"nan\") if len(set(y_np.tolist())) < 2 else roc_auc_score(y_np, probs)\n",
    "    return total_loss / n, auc\n",
    "\n",
    "def maml_second_order_train(\n",
    "    X2_tr, y2_tr, X2_val, y2_val,\n",
    "    base_model,\n",
    "    meta_iters=400,\n",
    "    n_tasks=8,\n",
    "    k_support_per_class=8,\n",
    "    k_query_per_class=16,\n",
    "    inner_steps=5,\n",
    "    inner_lr=1e-2,\n",
    "    meta_lr=5e-4,        # NOTE: smaller than FOMAML; 2nd-order is “stronger”\n",
    "    weight_decay=1e-4,\n",
    "    grad_clip=5.0,\n",
    "    eval_every=50,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    model = base_model.to(device)\n",
    "    meta_opt = torch.optim.Adam(model.parameters(), lr=meta_lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_auc = -float(\"inf\")\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for it in range(1, meta_iters + 1):\n",
    "        meta_opt.zero_grad()\n",
    "\n",
    "        # ---- sample batch of few-shot tasks from Group 2 ----\n",
    "        tasks = sample_task_batch(\n",
    "            X2_tr, y2_tr,\n",
    "            n_tasks=n_tasks,\n",
    "            k_support_per_class=k_support_per_class,\n",
    "            k_query_per_class=k_query_per_class\n",
    "        )\n",
    "\n",
    "        task_losses = []\n",
    "        for (Xs_np, ys_np, Xq_np, yq_np) in tasks:\n",
    "            Xs = torch.tensor(Xs_np, dtype=torch.float32, device=device)\n",
    "            ys = torch.tensor(ys_np.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "            Xq = torch.tensor(Xq_np, dtype=torch.float32, device=device)\n",
    "            yq = torch.tensor(yq_np.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "\n",
    "            # ---- inner loop: differentiable adaptation on support ----\n",
    "            adapted_params = inner_adapt_second_order(model, Xs, ys, steps=inner_steps, inner_lr=inner_lr)\n",
    "\n",
    "            # ---- query loss computed at adapted params ----\n",
    "            # functional forward with adapted params (keeps graph to base params)\n",
    "            logits_q = functional_call(model, adapted_params, (Xq,))\n",
    "            loss_q = bce(logits_q, yq)\n",
    "\n",
    "            # accumulate (sum) query losses across tasks for a single meta step\n",
    "            task_losses.append(loss_q)\n",
    "\n",
    "        # ---- meta-update: backprop through inner steps (2nd-order) ----\n",
    "        meta_loss = torch.stack(task_losses).mean()\n",
    "        meta_loss.backward()\n",
    "\n",
    "        # optional: gradient clipping for stability\n",
    "        if grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        meta_opt.step()\n",
    "\n",
    "        # ---- monitor on Group 2 validation (no adaptation) ----\n",
    "        if it % eval_every == 0:\n",
    "            val_loss, val_auc = evaluate_numpy(model, X2_val, y2_val)  # you can reuse earlier evaluate_numpy\n",
    "            print(f\"[MAML {it:04d}] Group2 Val: loss={val_loss:.4f} AUC={val_auc:.4f}\")\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"✅ True MAML done. Best Group2 Val AUC: {best_auc:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9dfb0d7-7c37-4b8b-8918-f28ace8c51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting to Group-1 (unchanged)\n",
    "\n",
    "# After meta-training, adaptation to Group-1 is the same idea as before: take a small, class-balanced support set from Group-1 train, run a few inner steps (you can reuse inner_adapt_second_order with the meta-trained base model), then evaluate on Group-1 val/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a4d11-7b58-4ab9-8868-633547c2d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_and_eval_group1_second_order(\n",
    "    meta_model, X1_tr, y1_tr, X1_val, y1_val, X1_test, y1_test,\n",
    "    shots_per_class=32, inner_steps=50, inner_lr=1e-3, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    # build small balanced support\n",
    "    import numpy as np\n",
    "    pos = np.where(y1_tr == 1.0)[0]\n",
    "    neg = np.where(y1_tr == 0.0)[0]\n",
    "    sp = np.random.choice(pos, shots_per_class, replace=(len(pos) < shots_per_class))\n",
    "    sn = np.random.choice(neg, shots_per_class, replace=(len(neg) < shots_per_class))\n",
    "    Xs = np.vstack([X1_tr[sp], X1_tr[sn]]).astype(np.float32)\n",
    "    ys = np.concatenate([np.ones(shots_per_class), np.zeros(shots_per_class)]).astype(np.float32)\n",
    "    idx = np.random.permutation(len(ys)); Xs, ys = Xs[idx], ys[idx]\n",
    "\n",
    "    Xs_t = torch.tensor(Xs, dtype=torch.float32, device=device)\n",
    "    ys_t = torch.tensor(ys.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "\n",
    "    # differentiable inner-loop on Group-1 support, then evaluate with adapted params\n",
    "    adapted_params = inner_adapt_second_order(meta_model, Xs_t, ys_t, steps=inner_steps, inner_lr=inner_lr)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    @torch.no_grad()\n",
    "    def eval_split(X_np, y_np):\n",
    "        X_t = torch.tensor(X_np, dtype=torch.float32, device=device)\n",
    "        y_t = torch.tensor(y_np.reshape(-1,1), dtype=torch.float32, device=device)\n",
    "        logits = functional_call(meta_model, adapted_params, (X_t,))\n",
    "        loss = bce(logits, y_t).item()\n",
    "        probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
    "        auc = float(\"nan\") if len(set(y_np.tolist())) < 2 else roc_auc_score(y_np, probs)\n",
    "        return loss, auc\n",
    "\n",
    "    g1_val_loss, g1_val_auc   = eval_split(X1_val,  y1_val)\n",
    "    g1_test_loss, g1_test_auc = eval_split(X1_test, y1_test)\n",
    "    return (g1_val_loss, g1_val_auc), (g1_test_loss, g1_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af6b6d-fd72-4a73-a794-4740c37bca15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7821009-9de6-4c32-b7ac-85b929c33611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to run\n",
    "\n",
    "# Instantiate your base model base = TabMLP(input_dim)\n",
    "\n",
    "# Call maml_second_order_train(...) on Group-2\n",
    "\n",
    "# Call adapt_and_eval_group1_second_order(...) on Group-1\n",
    "\n",
    "# When to pick second-order MAML\n",
    "\n",
    "# You have very small shots (e.g., 1–8 per class) and nonlinear models where the curvature matters.\n",
    "\n",
    "# You can afford higher memory/compute (inner steps build large graphs).\n",
    "\n",
    "# You saw FOMAML/Reptile plateau and want a (sometimes modest) bump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd07bf-c9a4-4c63-a067-15aa7896fb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f1c18-346b-4ce4-9b7a-758bddc67812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes — there are several recent and advanced meta-learning techniques beyond classic Model‑Agnostic Meta‑Learning (MAML) and Reptile that you might consider for your use-case (especially given your cold-start + account-rich lead scenario). I’ll highlight a few of the latest/interesting approaches, and then we can discuss which might fit best for your setting (Autodesk).\n",
    "\n",
    "# 🔍 Some recent meta-learning techniques\n",
    "\n",
    "\n",
    "# Online Meta-Learning / Continual Meta-Learning\n",
    "\n",
    "\n",
    "# For example, a recent pre-print titled Online Meta‑learning for AutoML in Real‑time (OnMAR) (2025) describes a meta-learning method for real-time AutoML, where a meta-learner monitors model performance and adapts the learning strategy continuously. arXiv\n",
    "\n",
    "\n",
    "# This kind of approach is useful when you have streaming data or tasks evolving over time (e.g., new geos, new products, new lead types) and your cold-start group (Group 1) dynamics may shift.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hybrid Meta-Learning: Metric + Optimization + Memory\n",
    "\n",
    "\n",
    "# Some recent works integrate metric-based (embedding or prototype space) + optimization-based (gradient adaptation) + memory-augmented networks (external memory) to get faster adaptation and better generalization. GeeksforGeeks\n",
    "\n",
    "\n",
    "# This could help when your “cold leads” (Group 1) have fewer features, and you want to leverage embeddings or similarity to known leads/accounts.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Meta-Learning for Personalization / Domain Shift\n",
    "\n",
    "\n",
    "# Techniques that consider heterogeneous tasks (domains change) or few‐shot personalization (e.g., in federated settings) — adapting to new distributions rather than just new classes. For instance, applying meta-learning for personalization in federated learning. arXiv\n",
    "\n",
    "\n",
    "# In your case, Group 1 vs Group 2 essentially represent different domains (no account vs account-rich). So domain‐adaptation meta‐learning could be appropriate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Neural Architecture / Optimizer Meta-Learning\n",
    "\n",
    "\n",
    "# Some methods meta-learn the optimizer or learning rule (rather than just model weights). This is less common in tabular business-data settings but could be interesting for sophisticated pipelines. lilianweng.github.io\n",
    "\n",
    "\n",
    "# For example: a meta-learner learns how to update model parameters in few steps (not just what the initial weights should be).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transformer-based / Representation-Meta-Learning\n",
    "\n",
    "\n",
    "# Meta‐learning that focuses on learning representations (embedding spaces) that generalize across tasks, rather than just fast adaptation of weights. Some newer architectures treat the encoder as meta‐learned and then fine‐tune small heads for new tasks. GeeksforGeeks+1\n",
    "\n",
    "\n",
    "# This seems relevant if you expect to get new products, geos, or personas in the future and want a representation that transfers well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 🧩 Which of these might fit for your Autodesk lead conversion use-case?\n",
    "# Given your scenario (Group 2: account-rich leads; Group 1: cold-start leads with fewer features) here’s how you might pick:\n",
    "\n",
    "\n",
    "# If you expect distributional change (new geos, new product lines) → go for online meta-learning or domain‐adaptation meta-learning\n",
    "\n",
    "\n",
    "# If you want to leverage embedding similarity (cold leads resemble known leads in some behavioral ways) → use hybrid metric + optimization meta-learning\n",
    "\n",
    "\n",
    "# If you want a strong, stable representation that generalizes across product/industry/geo → use representation-meta-learning (encoder as meta part)\n",
    "\n",
    "\n",
    "# If compute/memory is limited (tabular business use) → simpler methods (Reptile, FOMAML) might still be best practically\n",
    "\n",
    "\n",
    "\n",
    "# ✅ My Recommendation for You\n",
    "# Because you’re working with business tabular data (leads + accounts) rather than, say, image or language few-shot, I recommend this path:\n",
    "\n",
    "\n",
    "# Start with your Reptile / FOMAML implementation (as you already have) — this gives you a solid baseline.\n",
    "\n",
    "\n",
    "# Then experiment with one of the newer techniques: e.g., representation meta‐learning (train a shared encoder on Group 2 tasks, then fine-tune small heads on Group 1) or online meta-adaptation (if you have streaming leads over time).\n",
    "\n",
    "\n",
    "# Monitor which method yields better conversion prediction on Group 1 (cold starts) — compare AUC, calibration, adaptation speed (few shots).\n",
    "\n",
    "\n",
    "# Ensure practicality: tabular data, business constraints, interpretability, speed in deployment.\n",
    "\n",
    "\n",
    "\n",
    "# If you like, I can pull together a short list of ~5 recent “state‐of‐the‐art meta-learning” papers (2022-2025) relevant to tabular/industrial settings — we can pick one to implement or adapt for your project. Would that be helpful?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
